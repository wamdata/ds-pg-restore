services:
  swarm-cronjob:
    image: crazymax/swarm-cronjob:1.14.0
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    environment:
      - "TZ=Europe/Brussels"
      - "LOG_LEVEL=info"
      - "LOG_JSON=false"
    restart: unless-stopped
    deploy:
      placement:
        constraints:
          - node.role == manager

  sync:
    image: ghcr.io/wamdata/ds-pg-restore:main # replace main by the version
    volumes:
      - "sync_data:/app/data"
    environment:
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_KEY=${S3_KEY}
      - PRE_PROCESSING_SQL=/app/data/pre-process.sql
      - POST_PROCESSING_SQL=/app/data/post-process.sql
      - POSTGRES_HOST=postgres
    secrets:
      - postgres_password
      - aws_access_key_id
      - aws_secret_access_key
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        - "swarm.cronjob.enable=true"
        - "swarm.cronjob.schedule=* * * * *" # Run every minute
        - "swarm.cronjob.skip-running=true"
      replicas: 0
      restart_policy:
        condition: none

  postgres:
    image: postgres:17-alpine
    volumes:
      - "postgres_data:/var/lib/postgresql/data"
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    environment:
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
    secrets:
      - postgres_password
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      placement:
        constraints:
          - node.role == manager

secrets:
  postgres_password:
    external: true
  aws_access_key_id:
    external: true
  aws_secret_access_key:
    external: true

volumes:
  sync_data:
    driver: local
  postgres_data:
    driver: local
